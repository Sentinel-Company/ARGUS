import json

def filter_massive_data(input_file='data.json', output_file='data_optimized.json'):
    print("ğŸ§  ARGUS Veri Filtreleme BaÅŸladÄ± (Bu iÅŸlem biraz sÃ¼rebilir)...")
    
    with open(input_file, 'r', encoding='utf-8') as f:
        data = json.load(f)

    # 1. Her dÃ¼ÄŸÃ¼mÃ¼n kaÃ§ baÄŸlantÄ±sÄ± olduÄŸunu say
    link_counts = {}
    for link in data['links']:
        link_counts[link['source']] = link_counts.get(link['source'], 0) + 1
        link_counts[link['target']] = link_counts.get(link['target'], 0) + 1

    # 2. KRÄ°TER: Sadece 2 veya daha fazla baÄŸlantÄ±sÄ± olanlarÄ± tut 
    # (Tekil baÄŸlantÄ±lar genelde gÃ¼rÃ¼ltÃ¼dÃ¼r)
    important_nodes = {node_id for node_id, count in link_counts.items() if count >= 2}
    
    # 3. Yeni dÃ¼ÄŸÃ¼m ve baÄŸlantÄ± listesini oluÅŸtur
    new_nodes = [n for n in data['nodes'] if n['id'] in important_nodes]
    new_links = [l for l in data['links'] if l['source'] in important_nodes and l['target'] in important_nodes]

    # 4. Kaydet (BoÅŸluksuz formatta)
    optimized_data = {"nodes": new_nodes, "links": new_links}
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(optimized_data, f, separators=(',', ':'))

    print(f"âœ… FÄ°LTRELEME TAMAMLANDI!")
    print(f"ğŸ“Š Eski DÃ¼ÄŸÃ¼m: {len(data['nodes'])} -> Yeni DÃ¼ÄŸÃ¼m: {len(new_nodes)}")
    print(f"ğŸ’¾ Yeni dosya: {output_file} (Boyut ciddi oranda dÃ¼ÅŸtÃ¼)")

if __name__ == "__main__":
    filter_massive_data()